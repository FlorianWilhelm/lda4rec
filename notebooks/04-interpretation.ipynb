{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "from functools import partial\n",
    "import itertools\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pingouin as pg\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "#import pingouin as pg\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set_context(\"poster\")\n",
    "sns.set(rc={\"figure.figsize\": (16, 12.0)})\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import kendalltau, rankdata, spearmanr, pearsonr, ttest_rel\n",
    "import torch.nn.functional as F\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 120)\n",
    "pd.set_option(\"display.max_columns\", 120)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, stream=sys.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lda4rec.datasets import Interactions, DataLoader, random_train_test_split, MOVIELENS_1M,MetaData, get_dataset, items_per_user_train_test_split\n",
    "import lda4rec.evaluations as lda_eval\n",
    "from lda4rec.estimators import MFEst, PopEst, LDA4RecEst, SNMFEst\n",
    "from lda4rec.utils import process_ids, cmp_ranks, Config, split_along_dim_apply, plot_cat\n",
    "from lda4rec import lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.optim as optim\n",
    "import torch\n",
    "from pyro.distributions import constraints\n",
    "from pyro.infer import SVI, Predictive, Trace_ELBO, TraceEnum_ELBO, config_enumerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:neptune.internal.hardware.gpu.gpu_monitor:Info (NVML): NVML Shared Library Not Found. GPU usage metrics may not be reported. For more information, see https://docs-legacy.neptune.ai/logging-and-managing-experiment-results/logging-experiment-data.html#hardware-consumption \n",
      "offline/0ad00974-db85-4182-a956-86387fcf2d43\n",
      "Remember to stop your run once youâ€™ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<neptune.new.run.Run at 0x7f92ec3370d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import neptune.new as neptune\n",
    "# init dummy neptune to avoid problems with logging\n",
    "neptune.init(mode='offline') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icecream import ic, install\n",
    "\n",
    "install()\n",
    "# configure icecream\n",
    "def ic_str(obj):\n",
    "    if hasattr(obj, \"shape\"):\n",
    "        return f\"{obj} \"  #\n",
    "    else:\n",
    "        return str(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic.configureOutput(argToStringFunction=ic_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 19 is goodbooks dim 128, 33 is movielens dim 64\n",
    "cfg = Config(Path('../configs/exp_19.yaml'))\n",
    "exp_cfg = cfg[\"experiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': 'goodbooks',\n",
       " 'dataset_seed': 1729,\n",
       " 'est_params': {'batch_size': 256,\n",
       "  'embedding_dim': 128,\n",
       "  'learning_rate': 0.001,\n",
       "  'n_iter': 200},\n",
       " 'estimator': 'MFEst',\n",
       " 'interaction_pivot': 0,\n",
       " 'max_user_interactions': 200,\n",
       " 'min_user_interactions': 20,\n",
       " 'model_seed': 1729,\n",
       " 'train_test_split': 'items_per_user_train_test_split'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, data_rng = lda_eval.get_train_test_data(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = lda_eval.load_model(Path('../models'), cfg, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "v, t, h, b = est.get_lda_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Correlation of Cohorts and User interaction's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T</th>\n",
       "      <th>dof</th>\n",
       "      <th>alternative</th>\n",
       "      <th>p-val</th>\n",
       "      <th>CI95%</th>\n",
       "      <th>cohen-d</th>\n",
       "      <th>BF10</th>\n",
       "      <th>power</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>T-test</th>\n",
       "      <td>29.975105</td>\n",
       "      <td>53422</td>\n",
       "      <td>greater</td>\n",
       "      <td>4.381105e-196</td>\n",
       "      <td>[177798066972580.78, inf]</td>\n",
       "      <td>0.183153</td>\n",
       "      <td>2.915e+191</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                T    dof alternative          p-val  \\\n",
       "T-test  29.975105  53422     greater  4.381105e-196   \n",
       "\n",
       "                            CI95%   cohen-d        BF10  power  \n",
       "T-test  [177798066972580.78, inf]  0.183153  2.915e+191    1.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ids, log_probs = lda_eval.cohort_user_interaction_log_probs(train, v, h, rng=data_rng)\n",
    "pg.ttest(log_probs[:, 1], log_probs[:, 0], paired=True, alternative='greater')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Popularity Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = lda_eval.popularity_ranking_corr(train, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KendalltauResult(correlation=0.22118408993158703, pvalue=8.119494492245568e-241)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare Kendall's tau to http://polisci.usca.edu/apls301/Text/Chapter%2012.%20Significance%20and%20Measures%20of%20Association.htm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Conformity to Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_pops = lda_eval.get_empirical_pops(train)\n",
    "corr = lda_eval.conformity_interaction_pop_ranking_corr(emp_pops, (1/t).numpy(), train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KendalltauResult(correlation=-0.03048729326166538, pvalue=4.121011716330912e-26)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = lda_eval.conformity_interaction_pop_ranking_corr(b, (1/t).numpy(), train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KendalltauResult(correlation=-0.05989634446473608, pvalue=8.888821688879722e-96)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## User Finger Printing and Interaction correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids, good_twins, bad_twins, rnd_twins = lda_eval.find_good_bad_rnd_twins(v, n_users=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_jacs = lda_eval.get_twin_jacs(user_ids, good_twins, train)\n",
    "bad_jacs = lda_eval.get_twin_jacs(user_ids, bad_twins, train)\n",
    "rnd_jacs = lda_eval.get_twin_jacs(user_ids, rnd_twins, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T</th>\n",
       "      <th>dof</th>\n",
       "      <th>alternative</th>\n",
       "      <th>p-val</th>\n",
       "      <th>CI95%</th>\n",
       "      <th>cohen-d</th>\n",
       "      <th>BF10</th>\n",
       "      <th>power</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>T-test</th>\n",
       "      <td>20.157734</td>\n",
       "      <td>99</td>\n",
       "      <td>greater</td>\n",
       "      <td>4.028075e-37</td>\n",
       "      <td>[0.13, inf]</td>\n",
       "      <td>2.841054</td>\n",
       "      <td>6.249e+33</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                T  dof alternative         p-val        CI95%   cohen-d  \\\n",
       "T-test  20.157734   99     greater  4.028075e-37  [0.13, inf]  2.841054   \n",
       "\n",
       "             BF10  power  \n",
       "T-test  6.249e+33    1.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg.ttest(good_jacs, bad_jacs, paired=True, alternative='greater')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T</th>\n",
       "      <th>dof</th>\n",
       "      <th>alternative</th>\n",
       "      <th>p-val</th>\n",
       "      <th>CI95%</th>\n",
       "      <th>cohen-d</th>\n",
       "      <th>BF10</th>\n",
       "      <th>power</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>T-test</th>\n",
       "      <td>14.918771</td>\n",
       "      <td>99</td>\n",
       "      <td>greater</td>\n",
       "      <td>2.258553e-27</td>\n",
       "      <td>[0.1, inf]</td>\n",
       "      <td>2.070825</td>\n",
       "      <td>1.603e+24</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                T  dof alternative         p-val       CI95%   cohen-d  \\\n",
       "T-test  14.918771   99     greater  2.258553e-27  [0.1, inf]  2.070825   \n",
       "\n",
       "             BF10  power  \n",
       "T-test  1.603e+24    1.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg.ttest(good_jacs, rnd_jacs, paired=True, alternative='greater')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
